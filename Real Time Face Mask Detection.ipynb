{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "98179efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in e:\\anaconda\\lib\\site-packages (4.8.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\family\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\family\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\family\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\family\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\family\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\family\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from skimage.io import imread\n",
    "from bs4 import BeautifulSoup\n",
    "from skimage.feature import hog\n",
    "from skimage import io, transform\n",
    "from sklearn import preprocessing\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2a1b9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "# iterate over the subfolders in the train data folder\n",
    "for root, dirs, files in os.walk( r'\\Users\\Family\\Downloads\\archive\\images'):\n",
    "     for file_name in files:\n",
    "        # check if the file is a text file\n",
    "        if file_name.endswith('.png'):\n",
    "           file_path = os.path.join(root, file_name)\n",
    "           # read the image data\n",
    "           img = imread(file_path)\n",
    "           # resize the image\n",
    "           resized_img = resize(img, (128, 64))\n",
    "           # reshape the image to match the expected format of hog\n",
    "           hog_img = resized_img.reshape((resized_img.shape[0], resized_img.shape[1], -1))\n",
    "           # calculate the HOG features\n",
    "           #creating hog features \n",
    "           fd, hog_image = hog(hog_img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                cells_per_block=(2, 2), visualize=True,multichannel=True)\n",
    "           l.append(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "25186e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "i = 0\n",
    "# iterate over the subfolders in the train data folder\n",
    "for root, dirs, files in os.walk( r'\\Users\\Family\\Downloads\\archive\\annotations'):\n",
    "     for file_name in files:\n",
    "        # Reading the data inside the xml\n",
    "        # file to a variable under the name\n",
    "        # data\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = f.read()\n",
    "        # Passing the stored data inside\n",
    "        # the beautifulsoup parser, storing\n",
    "        # the returned object\n",
    "        Bs_data = BeautifulSoup(data, \"xml\")\n",
    "        # Finding all instances of tag\n",
    "        # `unique`\n",
    "        b_unique = Bs_data.find_all('name')\n",
    "        xmin = Bs_data.find_all('xmin')\n",
    "        ymin = Bs_data.find_all('ymin')\n",
    "        xmax = Bs_data.find_all('xmax')\n",
    "        ymax = Bs_data.find_all('ymax')\n",
    "        \n",
    "        for j in range(0,len(b_unique)):\n",
    "            \n",
    "            match1 = re.search(r\"<xmin>(.*?)</xmin>\", str(xmin[j]))\n",
    "            match2 = re.search(r\"<ymin>(.*?)</ymin>\", str(ymin[j]))\n",
    "            match3 = re.search(r\"<xmax>(.*?)</xmax>\", str(xmax[j]))\n",
    "            match4 = re.search(r\"<ymax>(.*?)</ymax>\", str(ymax[j]))\n",
    "            match5 = re.search(r\"<name>(.*?)</name>\", str(b_unique[j])) \n",
    "            \n",
    "            body_of_tag1 = match1.group(1)\n",
    "            body_of_tag2 = match2.group(1)\n",
    "            body_of_tag3 = match3.group(1)\n",
    "            body_of_tag4 = match4.group(1)\n",
    "            body_of_tag5 = match5.group(1)\n",
    "           \n",
    "            temp = np.array([body_of_tag1,body_of_tag2,body_of_tag3,body_of_tag4])\n",
    "            \n",
    "            x.append(np.append(l[i],temp))\n",
    "            y.append(body_of_tag5)\n",
    "            \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77203107",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af921687",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state= 0, train_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0f3ea0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "74434482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of SVC: 0.8201350521792511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#Create a svm Classifier\n",
    "clf = SVC(kernel='rbf') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy of SVC: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "241111ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of Logistic Regression: 0.8192142418661755\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(solver='newton-cg',C=0.01)\n",
    "best_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = best_model.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy of Logistic Regression: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8b4bd9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of GradientBoosting: 0.8173726212400245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train a new model with the best hyperparameters on the combined training and validation sets\n",
    "Gradient_Boosting_model = GradientBoostingClassifier(n_estimators=10,max_depth=3)\n",
    "Gradient_Boosting_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = Gradient_Boosting_model.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy of GradientBoosting: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a3bcca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of DecisionTree: 0.807243707796194\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier( random_state = 10 ,max_depth= 4,splitter='random',min_samples_leaf=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train_scaled,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test_scaled)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Test accuracy of DecisionTree:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
